---
title: "Google Capstone - Bike Case Study"
author: "Sebastian Suliborski"
date: "2022-11-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Case Study: How Does a Bike-Share Navigate Speedy Success?

This is the Cyclistic bike-share analysis case study from Google Data Analytics Certificate. In this case study I imagine that I work for a fictional company, Cyclistic. 

## Scenario

In the beginning is good to present the scenario of case study. It is as follows:\
"You are a junior data analyst working in the marketing analyst team at Cyclistic, a bike-share company in Chicago. The director of marketing believs the company's future success depends on maximizing the nubmer of annual membership.Therefore,
your team wants to understand how casual riders and annual members use Cyclistic bikes differently. From these insights,
your team will design a new marketing strategy to convert casual riders into annual members. But first, Cyclistic executives
must approve your recommendations, so they must be backed up with compelling data insights and professional data
visualizations.

I will follow the scenario based on six phases of analysis:\
1) Ask\
2) Prepare\
3) Proccess\
4) Analyze\
5) Share\
6) Act

## Ask

There is three guiding questions:\
1. How do annual members and casual riders use Cyclistic bikes differently?\
2. Why would casual riders buy Cyclistic annual memberships?\
3. How can Cyclistic use digital media to influence casual riders to become members?\

And for me the most important is first, how do annual and casual riders use bikes differently?\

In this report I should include those deliverables:\
1. A clear statement of the business task\
2. A description of all data sources used\
3. Documentation of any cleaning or manipulation of data\
4. A summary of your analysis\
5. Supporting vizzes and key findings\
6. Your top three recommendations based on your analysis.

## Prepare

In this case study I used RStudio 2022.07.2 Build 576, R version 4.2.0. Full case study was made in R and Tableau, but for this R markdown file I made second version only in RStudio.

Libraries:

```{r libraries}
library(tidyverse)
library(lubridate)
library(readr)
library(janitor)
library(ggplot2)
```

Data loading:

```{r loading}
d0 <- read.csv(file = "C:/Users/sebas/OneDrive/Pulpit/google data/gda_case_study/csvs/202111-divvy-tripdata.csv", 
               header = TRUE, sep = ',') 
d1 <- read.csv(file = "C:/Users/sebas/OneDrive/Pulpit/google data/gda_case_study/csvs/202112-divvy-tripdata.csv", 
               header = TRUE, sep = ',')
d2 <- read.csv(file = "C:/Users/sebas/OneDrive/Pulpit/google data/gda_case_study/csvs/202201-divvy-tripdata.csv", 
               header = TRUE, sep = ',')
d3 <- read.csv(file = "C:/Users/sebas/OneDrive/Pulpit/google data/gda_case_study/csvs/202202-divvy-tripdata.csv", 
               header = TRUE, sep = ',')
d4 <- read.csv(file = "C:/Users/sebas/OneDrive/Pulpit/google data/gda_case_study/csvs/202203-divvy-tripdata.csv", 
               header = TRUE, sep = ',')
d5 <- read.csv(file = "C:/Users/sebas/OneDrive/Pulpit/google data/gda_case_study/csvs/202204-divvy-tripdata.csv", 
               header = TRUE, sep = ',')
d6 <- read.csv(file = "C:/Users/sebas/OneDrive/Pulpit/google data/gda_case_study/csvs/202205-divvy-tripdata.csv", 
               header = TRUE, sep = ',')
d7 <- read.csv(file = "C:/Users/sebas/OneDrive/Pulpit/google data/gda_case_study/csvs/202206-divvy-tripdata.csv", 
               header = TRUE, sep = ',')
d8 <- read.csv(file = "C:/Users/sebas/OneDrive/Pulpit/google data/gda_case_study/csvs/202207-divvy-tripdata.csv", 
               header = TRUE, sep = ',')
d9 <- read.csv(file = "C:/Users/sebas/OneDrive/Pulpit/google data/gda_case_study/csvs/202208-divvy-tripdata.csv", 
               header = TRUE, sep = ',')
d10 <- read.csv(file = "C:/Users/sebas/OneDrive/Pulpit/google data/gda_case_study/csvs/202209-divvy-publictripdata.csv", 
                header = TRUE, sep = ',')
d11 <- read.csv(file = "C:/Users/sebas/OneDrive/Pulpit/google data/gda_case_study/csvs/202210-divvy-tripdata.csv", 
                header = TRUE, sep = ',')

```

I have data from last 12 months, between november 2021 to october 2022, provided by the fiction Cyclistic company.
Data merging: 

```{r merging}
raw_data <- rbind(d0, d1, d2, d3, d4, d5, d6, d7, d8, d9, d10, d11)
```

View merged data:

```{r summary}
summary(raw_data)
str(raw_data)
unique(raw_data$rideable_type)
```

Now it is very large dataset with more than 4 milion rows and 13 columns that contain:
- ride_id - id for each trip taken; char
- rideable_type - type of a bike, there is two types: electric_bike, classic_bike and docked_bike; char
- started_at - date and time of the start time; for now char, I will make it POSIXct
- ended_at - date and time of the end time; for now char, I will make it POSIXct
- start_station_name - name of the starting station; char
- start_station_id - id of the starting station; char
- end_station_name - name of the ending station;char
- end_station_id - id of the ending station; char
- start_lat - latitude of the starting point
- start_lng - longitude of the starting point
- end_lat - latitude of the ending point
- end_lng - longitude of the ending point
- member_casual - client status - member or casual; char

I will create four new columns:
- ride_length - time of the trip in seconds
- weekday - weekday of the trip, 7 levels from Monday to Sunday
- month - month of the trip; int, 1-12
- day - day of the trip; int, 1-31

## Proccess

Removing empty cols and rows:

```{r empty}
raw_data <- remove_empty(raw_data, which = c("cols"))
raw_data <- remove_empty(raw_data, which = c("rows"))
dim(raw_data)
```

Cleaning names:

```{r names}
clean_data <- clean_names(raw_data)
```

NA values:

```{r NA}
colSums(is.na(clean_data))

clean_data <- clean_data[complete.cases(clean_data), ]

colSums(is.na(clean_data))
```

I will not need cols with long and lat. I will analyze without geografic point of view. 

Remove cols with long and lat:

```{r remove}
remove_data <- clean_data %>%
  select(-c(start_lat, start_lng, end_lat, end_lng))
View(remove_data)
```

I need date&time data time, so I need to convert time type:

```{r datetime}
remove_data$started_at <- as.POSIXct(remove_data$started_at, "%Y-%m-%d %H:%M:%S", tz="Europe/London")
remove_data$ended_at <- as.POSIXct(remove_data$ended_at, "%Y-%m-%d %H:%M:%S", tz="Europe/London")

str(remove_data)
```

Remove started_at greater than ended_at:

```{r zero}
fremove_data <- remove_data %>%
  filter(remove_data$started_at < remove_data$ended_at)
```

Add column ride_length for better understand and visual time of trips:

```{r ride_length}
add_data <- fremove_data %>%
  mutate(ride_length = as.numeric(fremove_data$ended_at - fremove_data$started_at))
summary(add_data$ride_length)
```

Add weekday:

```{r weekday}
add_data <- add_data %>%
  mutate(weekday = paste(strftime(add_data$ended_at, "%u")))
unique(add_data$weekday)
```

Aggregation data for each day and month (I made aggregation for weekday, but I also could need for month and days):

```{r days/months}
add_data <- add_data %>%
    mutate(month = paste(strftime(add_data$started_at, "%Y"),
                              "-",
                              strftime(add_data$started_at, "%m"),
                              paste("(",strftime(add_data$started_at, "%b"), ")", sep="")))
unique(add_data$month)

add_data <- add_data %>%
  mutate(day = paste(strftime(add_data$ended_at, "%d")))
add_data$day <- as.integer(add_data$day)
unique(add_data$day)
```

Data summary after cleaning:

```{r summary2}
str(add_data)
summary(add_data)

```

## Analyze

Guiding questions: \
- ogranizing and formatting\
- what I discovered\
- trends and relationships\

So I need to:\
- aggregate data\
- organize and format them\
- perform calculations\
- identify trends and relationships

```{r}
ggplot(add_data, aes(member_casual, fill = member_casual)) +
    geom_bar()
```
There is much more data for members. 
Checking the quantities for months also can have value:

```{r}
add_data %>%
  ggplot(aes(month, fill = member_casual)) +
  geom_bar() +
  coord_flip()
```

Descriptive analysis on ride_length (in seconds):

```{r anal}
mean(add_data$ride_length) #straight average (total ride length / rides)
median(add_data$ride_length) #midpoint number in the ascending array of ride lengths
max(add_data$ride_length) #longest ride
min(add_data$ride_length) #shortest ride
```

Ride_length mean is ~998 seconds.Max - 2057644, min 1 second - and there is many 1 sec trips, so it's neccessary to remove too short rides. It could be when member rented bike but there was problem with bike or app, or it was some other error. 2057644 is equal to almost 24 days - bike was lost or robbed. Outlier results should be removed for better understanding and visualizating of data.

```{r}
ventiles = quantile(add_data$ride_length, seq(0, 1, by=0.05))
add_data <- add_data %>% 
    filter(ride_length > as.numeric(ventiles['5%'])) %>%
    filter(ride_length < as.numeric(ventiles['95%']))
summary(add_data$ride_length)
```
Compare casuals to members:

```{r cas-mem}
aggregate(add_data$ride_length ~ add_data$member_casual, FUN = mean)
aggregate(add_data$ride_length ~ add_data$member_casual, FUN = median)
aggregate(add_data$ride_length ~ add_data$member_casual, FUN = max)
aggregate(add_data$ride_length ~ add_data$member_casual, FUN = min)
```

Casuals rides longer than members.

Average ride time by each day for members vs casual users:

```{r avg}
aggregate(add_data$ride_length ~ add_data$member_casual + add_data$weekday, FUN = mean)
```

Both - casuals and members riding the most at the fridays and saturdays. Differences between individual days are smaller in member group. So we can conclude that members often go to work on bikes, casuals probalby often just rides "casual" like on trips and just for the ride at the day off.

Fix order of dayweek:

```{r dayweek_names}
add_data$weekday <- ordered(add_data$weekday, levels=c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))
```

What about rideable type? On which type of bike rides more members and casuals?

```{r}
ggplot(add_data, aes(rideable_type, fill=member_casual)) +
    geom_bar() +
    coord_flip()
```
Casuals like more electric bikes than classic bikes. It can be assumed that they value convenience more than price (of course, if electric bikes cost more, which is probably). Also we can see that only casuals ride on docked bike.

Analyze data by type and weekday:

```{r type_day}
add_data %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>%  
  group_by(member_casual, weekday) %>%  
  summarise(number_of_rides = n()						 
            ,average_duration = mean(ride_length)) %>% 	
  arrange(member_casual, weekday)							
```

Again - casual rides longer than members and the biggest number of rides for casuals is at the weekend and members in tuesday 
and thursday. The longest rides for casuals are in saturday and sundays, for members it's similar at all days.

Viz number of rides by rider type:

```{r viz_riders_type}
add_data %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = number_of_rides, fill = member_casual)) +
  geom_col(position = "dodge")
```

Viz for rides length by weekday and type of members:

```{r viz_length}
add_data %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = average_duration, fill = member_casual)) +
  geom_col(position = "dodge")
```

Duration vs distance:

```{r}
ggplot(filter(add_data, add_data$ride_length < 3600)) +
  geom_histogram(mapping = aes(x = ride_length)) +
  facet_wrap(~member_casual)
```

These two vizzes confirms previous conclusions.

Distance travelled in meters:

```{r}
ggplot(filter(add_data, add_data$ride_length < 10000)) +
  geom_density(mapping = aes(x = ride_length)) +
  facet_wrap(~member_casual)
```

```{r}
add_data %>%
  ggplot(aes(month, fill=member_casual)) +
    geom_bar()  +
  coord_flip()
```
    
## Share

After analysis, many lines of code and vizzes it's time for share results answering on question: "How can we convert casuals to members?".
There were many data - almost 6 milion observations, but there weren't enough information to fully answer this question. It could be better with gender, age and some other more accurate data like behavior of users when they were casuals and then members, however I can answer more or less based on the data I had. 
So, here some conlucions based on this dataset:
- Members using bikes similar throughout whole week except Saturday (small difference) and Sunday (bigger difference). Probably it's because they are mostly working people, but it isn't possible to say 100% because there is no data on whether the user is working or not, but pattern says enough.
- Casuals using bikes more at the weekends, especially Saturday.Can be assumed that is for recreation or for sport. These trips are longer than members trips in middle week.
- Classic bikes are most popular for members and electric for casuals. Docked bikes are used only by casuals.
- Many electric bikes has missing start or end station. This is not an case for marketing team, but for IT, there maybe some issues with registrating bikes.
- Casuals using bike longer than members, but members more.
- Most rides are in warm months like june, july, august - also months of the vacation. In the most cold months like january and february there only few casuals and even not many members (but for them difference is less), so marketing actions aren't needed in these months.

## Act

For our goal, "How can we convert casuals to members?" we can suggest:
- Increase renting price for the weekend for casuals or decrease renting price for members. It could make that some casuals take subscription for cheaper weekend trips. These trips also could be cheaper in a long yourneys. 
- We can create new, weekend subscription for the same goal as in first idea. Casuals who going to trips at the weekend could take it. They can drive car to work or work from home, so they don't need a classic subscription, but this new subscription should encourage them.
- We can provide a special service or promotions/loyalty cards and personal ads for members to motivate casuals to have a subscription. Marketing campaigns should work best in the spring and summer seasons, when the number of rides increases and peaks in the summer. Also we can have banners and leaflets close to most popular stations.
- Electric bikes - issue for IT team. Why is it missing and how to repair it.

There is four main recommendations for this dataset, but if it were more data like for age, gender and job of users then analysis could be more complex and bring some ideas for future analysis. 
